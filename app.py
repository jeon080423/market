import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import requests
from bs4 import BeautifulSoup
import json
from io import StringIO
from groq import Groq

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì£¼ì‹ ì‹œì¥ í•˜ë½ ì „ì¡° ì‹ í˜¸ ëª¨ë‹ˆí„°ë§", layout="wide")

# ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì • (10ë¶„ ê°„ê²©)
try:
    from streamlit_autorefresh import st_autorefresh
    st_autorefresh(interval=600000, key="datarefresh")
except ImportError:
    pass

# 2. Secretsì—ì„œ API Key ë¶ˆëŸ¬ì˜¤ê¸°
try:
    NEWS_API_KEY = st.secrets["news_api"]["api_key"]
    GROQ_API_KEY = st.secrets["groq"]["api_key"]
except KeyError:
    st.error("Secrets ì„¤ì •(API Key)ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    st.stop()

# Groq ì„¤ì • ë° ëª¨ë¸ ì´ˆê¸°í™”
try:
    client = Groq(api_key=GROQ_API_KEY)
except Exception as e:
    st.error(f"Groq ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# AI ë¶„ì„ í•¨ìˆ˜ ì •ì˜
@st.cache_data(ttl=3600)
def get_ai_analysis(prompt):
    try:
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="openai/gpt-oss-20b",
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"AI ë¶„ì„ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

COVID_EVENT_DATE = "2020-02-19"

try:
    ADMIN_ID = st.secrets["auth"]["admin_id"]
    ADMIN_PW = st.secrets["auth"]["admin_pw"]
except KeyError:
    ADMIN_ID = "admin_temp" 
    ADMIN_PW = "temp_pass"

SHEET_ID = "1eu_AeA54pL0Y0axkhpbf5_Ejx0eqdT0oFM3WIepuisU"
GSHEET_CSV_URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv"
GSHEET_WEBAPP_URL = "https://script.google.com/macros/s/AKfycbyli4kg7O_pxUOLAOFRCCiyswB5TXrA0RUMvjlTirSxLi4yz3tXH1YoGtNUyjztpDsb/exec" 

st.markdown("""
    <style>
    h1 { font-size: clamp(24px, 4vw, 48px) !important; }
    .guide-header { font-size: clamp(18px, 2.5vw, 28px) !important; font-weight: 600; margin-bottom: 45px !important; margin-top: 60px !important; padding-top: 10px !important; }
    .guide-text { font-size: clamp(14px, 1.2vw, 20px) !important; line-height: 1.8 !important; }
    div[data-testid="stMarkdownContainer"] table { width: 100% !important; table-layout: auto !important; margin-bottom: 10px !important; }
    div[data-testid="stMarkdownContainer"] table th, div[data-testid="stMarkdownContainer"] table td { font-size: clamp(12px, 1.1vw, 16px) !important; word-wrap: break-word !important; padding: 12px 4px !important; }
    hr { margin-top: 1rem !important; margin-bottom: 1rem !important; }
    .ai-analysis-box { background-color: #f0f7ff; padding: 15px 20px; border-radius: 10px; border-left: 5px solid #007bff; line-height: 1.65; font-size: 1.0rem; margin-bottom: 10px; }
    </style>
    """, unsafe_allow_html=True)

def get_kst_now():
    return datetime.now() + timedelta(hours=9)

st.title("KOSPI ìœ„í—˜ ëª¨ë‹ˆí„°ë§ (KOSPI Market Risk Index)")
st.markdown(f"""
ì´ ëŒ€ì‹œë³´ë“œëŠ” **í–¥í›„ 1ì£¼ì¼(5ê±°ë˜ì¼) ë‚´ì™¸**ì˜ ì‹œì¥ ë³€ë™ ìœ„í—˜ì„ í¬ì°©í•˜ëŠ”ë° ìµœì í™” ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  **ê²€ì¦ë˜ì§€ ì•Šì€ ëª¨ë¸** ì´ê¸°ë•Œë¬¸ì— **ì°¸ê³ ë§Œ** í•˜ì„¸ìš”.
(ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ KST: {get_kst_now().strftime('%mì›” %dì¼ %Hì‹œ %Më¶„')})
""")
st.markdown("---")

with st.expander("ğŸ“– ì§€ìˆ˜ ê°€ì´ë“œë¶"):
    st.subheader("1. ì§€ìˆ˜ ì‚°ì¶œ í•µì‹¬ ì§€í‘œ (Core Indicators)")
    st.write("""
    ë³¸ ëª¨ë¸ì˜ ì§€í‘œë“¤ì€ KOSPIì™€ì˜ **í†µê³„ì  ìƒê´€ê´€ê³„** ë° **í•˜ë½ ì„ í–‰ì„±**ì„ ê¸°ì¤€ìœ¼ë¡œ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.
    * **ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬**: ë¯¸êµ­ **S&P 500 ì§€ìˆ˜**ë¥¼ í™œìš©í•˜ë©°, í•œêµ­ ì¦ì‹œì™€ì˜ ê°•ë ¥í•œ ë™ì¡°í™” ê²½í–¥ì„ ë°˜ì˜í•©ë‹ˆë‹¤.
    * **í†µí™” ë° ìœ ë™ì„±**: **ì›/ë‹¬ëŸ¬ í™˜ìœ¨** ë° **ë‹¬ëŸ¬ ì¸ë±ìŠ¤(DXY)** ë¥¼ í†µí•´ ì™¸êµ­ì¸ ìë³¸ ìœ ì¶œ ì••ë ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
    * **ì‹œì¥ ì‹¬ë¦¬**: **VIX(ê³µí¬ ì§€ìˆ˜)** ë¥¼ í†µí•´ íˆ¬ììì˜ ë¶ˆì•ˆ ì‹¬ë¦¬ì™€ ë³€ë™ì„± ì „ì¡°ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
    * **ì‹¤ë¬¼ ê²½ì œ**: ê²½ê¸° ì„ í–‰ ì§€í‘œì¸ **êµ¬ë¦¬ ê°€ê²©(Copper)** ê³¼ **ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨**ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    """)
    st.divider()
    st.subheader("2. ì„ í–‰ì„± ë¶„ì„ ë²”ìœ„ ë° íš¨ê³¼ (Lag Analysis)")
    st.markdown("#### **â‘  ì„ í–‰ì„± ë¶„ì„ ë²”ìœ„ (Lag Optimization)**")
    st.write("""
    * **ë‹¨ê¸° ì„ í–‰ì„± (1~5ì¼)**: í˜„ì¬ ëª¨ë¸ì˜ `find_best_lag` í•¨ìˆ˜ëŠ” ê° ì§€í‘œì™€ KOSPI ê°„ì˜ ìƒê´€ê³„ìˆ˜ê°€ ê°€ì¥ ë†’ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì§€ì—° ì‹œê°„ì„ 0ì¼ì—ì„œ 5ì¼ ì‚¬ì´ì—ì„œ ì°¾ìŠµë‹ˆë‹¤. ì´ëŠ” ë§¤í¬ë¡œ ì§€í‘œì˜ ë³€í™”ê°€ êµ­ë‚´ ì¦ì‹œì— ì¦‰ê°ì  í˜¹ì€ ìˆ˜ì¼ ë‚´ì— ë°˜ì˜ë˜ëŠ” ë‹¨ê¸°ì  'ì „ì¡° ì‹ í˜¸'ë¥¼ í¬ì°©í•˜ëŠ” ë° ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    * **ì¤‘ì¥ê¸° ì„ í–‰ì„± (1~3ê°œì›”)**: 'ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨'ì™€ ê°™ì€ íŠ¹ì • ì§€í‘œëŠ” ìˆ˜ê°œì›” ì´ìƒì˜ ì‹œì°¨ë¥¼ ë‘ê³  ì‹¤ë¬¼ ê²½ê¸°ì— ì˜í–¥ì„ ì£¼ì§€ë§Œ, ë³¸ ëŒ€ì‹œë³´ë“œëŠ” ì£¼ì‹ ì‹œì¥ì˜ ë‹¨ê¸° í•˜ë½ ìœ„í—˜ ëª¨ë‹ˆí„°ë§ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆì–´ ëª¨ë¸ ë‚´ë¶€ì ìœ¼ë¡œëŠ” ìµœê·¼ì˜ ë³€ë™ ê¸°ì—¬ë„ë¥¼ ìš°ì„ ì‹œí•©ë‹ˆë‹¤.
    """)
    st.markdown("#### **â‘¡ ì§€í‘œë³„ íŠ¹ì„±ì— ë”°ë¥¸ ì„ í–‰ íš¨ê³¼**")
    st.write("""
    * **ê³µí¬ ì§€ìˆ˜(VIX) ë° í™˜ìœ¨**: í†µìƒì ìœ¼ë¡œ ë‹¹ì¼ í˜¹ì€ 1~2ì¼ ë‚´ì™¸ì˜ ë§¤ìš° ì§§ì€ ì„ í–‰ì„±ì„ ë³´ì´ë©° ì‹œì¥ì˜ ì¦‰ê°ì ì¸ ì‹¬ë¦¬ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.
    * **êµ¬ë¦¬ ê°€ê²© ë° ë¬¼ë™ëŸ‰(BDRY)**: ì‹¤ë¬¼ ê²½ê¸°ë¥¼ ë°˜ì˜í•˜ë¯€ë¡œ ì£¼ê°€ì§€ìˆ˜ë³´ë‹¤ ìˆ˜ì¼ì—ì„œ ìˆ˜ì£¼ ì•ì„œ ì¶”ì„¸ì  ë³€í™”ë¥¼ ë³´ì´ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.
    * **ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨**: ì‹¤ì œ ê²½ê¸° ì¹¨ì²´ëŠ” 6ê°œì›”~1ë…„ ì´ìƒì˜ ì‹œì°¨ë¥¼ ë‘ê³  ë°œìƒí•  ìˆ˜ ìˆìœ¼ë‚˜, ê¸ˆìœµ ì‹œì¥ì€ ì´ë¥¼ ì„ ë°˜ì˜í•˜ì—¬ ìˆ˜ì£¼ ë‚´ì— í•˜ë½ ì••ë ¥ì„ ë°›ê¸° ì‹œì‘í•©ë‹ˆë‹¤.
    """)
    st.markdown("#### **â‘¢ ìš”ì•½**")
    st.info("ë³¸ ëŒ€ì‹œë³´ë“œì˜ ìœ„í—˜ ì§€ìˆ˜ëŠ” ìˆ˜ê°œì›” ë‹¨ìœ„ì˜ ê±°ì‹œì  ê²½ì œ ì§€í‘œë³´ë‹¤ëŠ”, **í–¥í›„ 1ì£¼ì¼(5ê±°ë˜ì¼) ë‚´ì™¸**ì˜ ì‹œì¥ ë³€ë™ ìœ„í—˜ì„ í¬ì°©í•˜ê³  ëŒ€ë¹„í•˜ëŠ”ë° ìµœì í™”ë˜ì–´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.divider()
    st.subheader("3. ìˆ˜ë¦¬ì  ì‚°ì¶œ ê³µì‹")
    @st.cache_data
    def get_math_formulas():
        st.markdown("#### **â‘  ì‹œì°¨ ìƒê´€ê´€ê³„ (Time-Lagged Correlation)**")
        st.latex(r"\rho(k) = \frac{Cov(X_{t-k}, Y_t)}{\sigma_{X_{t-k}} \sigma_{Y_t}} \quad (0 \le k \le 5)")
        st.markdown("#### **â‘¡ í†µê³„ì  ë³€ë™ ê¸°ì—¬ë„ ë¶„ì„ (Feature Importance)**")
        st.latex(r"Importance_i = |\beta_i| \times \sigma_{X_i}")
        st.markdown("#### **â‘¢ Z-Score í‘œì¤€í™” (Standardization)**")
        st.latex(r"Z = \frac{x - \mu}{\sigma}")
    get_math_formulas()

@st.cache_data(ttl=60) # ìµœì‹  ì—…ë°ì´íŠ¸ í™•ì¸ì„ ìœ„í•´ 1ë¶„ìœ¼ë¡œ ë‹¨ì¶•
def load_data():
    # ì¢…ë£Œì¼ ì„¤ì •: ì˜¤ëŠ˜ì´ KST ê¸°ì¤€ ì¥ì´ ëë‚¬ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‚´ì¼ ë‚ ì§œê¹Œì§€ ìš”ì²­
    end_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')
    start_date = "2019-01-01"
    
    tickers = {
        "kospi": "^KS11", "sp500": "^GSPC", "fx": "KRW=X", 
        "us10y": "^TNX", "us2y": "^IRX", "vix": "^VIX", 
        "copper": "HG=F", "freight": "BDRY", "wti": "CL=F", "dxy": "DX-Y.NYB"
    }
    
    # auto_adjust=True ì¶”ê°€í•˜ì—¬ ì¢…ê°€ ë°ì´í„° ë¬´ê²°ì„± ê°•í™”
    data = yf.download(list(tickers.values()), start=start_date, end=end_date, interval='1d', auto_adjust=True)['Close']
    
    sector_tickers = {
        "ë°˜ë„ì²´": "005930.KS", "ìë™ì°¨": "005380.KS", "2ì°¨ì „ì§€": "051910.KS",
        "ë°”ì´ì˜¤": "207940.KS", "ì¸í„°ë„·": "035420.KS", "ê¸ˆìœµ": "055550.KS",
        "ì² ê°•": "005490.KS", "ë°©ì‚°": "047810.KS", "ìœ í‹¸ë¦¬í‹°": "015760.KS"
    }
    sector_raw = yf.download(list(sector_tickers.values()), period="5d")['Close']
    
    return (
        data[[tickers["kospi"]]], data[[tickers["sp500"]]], data[[tickers["fx"]]], 
        data[[tickers["us10y"]]], data[[tickers["us2y"]]], data[[tickers["vix"]]], 
        data[[tickers["copper"]]], data[[tickers["freight"]]], data[[tickers["wti"]]], 
        data[[tickers["dxy"]]], sector_raw, sector_tickers
    )

@st.cache_data(ttl=1800)
def get_market_news():
    api_url = "https://newsapi.org/v2/everything"
    params = {"q": "stock market risk OR recession OR inflation", "sortBy": "publishedAt", "language": "en", "pageSize": 5, "apiKey": NEWS_API_KEY}
    try:
        res = requests.get(api_url, params=params, timeout=10)
        data = res.json()
        if data.get("status") == "ok":
            news_items = []
            for article in data.get("articles", []):
                news_items.append({"title": article["title"], "link": article["url"]})
            return news_items
        return []
    except:
        return []

@st.cache_data(ttl=10) 
def load_board_data():
    try:
        res = requests.get(f"{GSHEET_CSV_URL}&cache_bust={datetime.now().timestamp()}", timeout=10)
        res.encoding = 'utf-8' 
        if res.status_code == 200:
            df = pd.read_csv(StringIO(res.text), dtype=str).fillna("")
            return df.to_dict('records')
        return []
    except:
        return []

def save_to_gsheet(date, author, content, password, action="append"):
    try:
        payload = {"date": str(date), "author": str(author), "content": str(content), "password": str(password), "action": action}
        res = requests.post(GSHEET_WEBAPP_URL, data=json.dumps(payload), timeout=15)
        if res.status_code == 200:
            st.cache_data.clear()
            return True
        return False
    except Exception as e:
        st.error(f"ì—°ë™ ì—ëŸ¬: {e}")
        return False

try:
    with st.spinner('ì‹œì°¨ ìƒê´€ê´€ê³„ ë° ê°€ì¤‘ì¹˜ ë¶„ì„ ì¤‘...'):
        kospi, sp500, fx, bond10, bond2, vix_data, copper_data, freight_data, wti_data, dxy_data, sector_raw, sector_map = load_data()

    def get_clean_series(df):
        if df is None or df.empty: return pd.Series(dtype='float64')
        if isinstance(df, pd.DataFrame):
            df = df.iloc[:, 0]
        # íƒ€ì„ì¡´ ì œê±° ë° ì¤‘ë³µ ì œê±° (ê°€ì¥ ìµœì‹  ê°’ ìœ ì§€)
        df.index = pd.to_datetime(df.index).tz_localize(None)
        return df[~df.index.duplicated(keep='last')]

    ks_s = get_clean_series(kospi).ffill()
    sp_s = get_clean_series(sp500).reindex(ks_s.index).ffill()
    fx_s = get_clean_series(fx).reindex(ks_s.index).ffill()
    b10_s = get_clean_series(bond10).reindex(ks_s.index).ffill()
    b2_s = get_clean_series(bond2).reindex(ks_s.index).ffill()
    vx_s = get_clean_series(vix_data).reindex(ks_s.index).ffill()
    cp_s = get_clean_series(copper_data).reindex(ks_s.index).ffill()
    fr_s = get_clean_series(freight_data).reindex(ks_s.index).ffill()
    wt_s = get_clean_series(wti_data).reindex(ks_s.index).ffill()
    dx_s = get_clean_series(dxy_data).reindex(ks_s.index).ffill()
    
    yield_curve = b10_s - b2_s
    ma20 = ks_s.rolling(window=20).mean()

    def get_hist_score_val(series, current_idx, inverse=False):
        try:
            sub = series.loc[:current_idx].iloc[-252:]
            if len(sub) < 10: return 50.0
            min_v, max_v = sub.min(), sub.max(); curr_v = series.loc[current_idx]
            if max_v == min_v: return 50.0
            return ((max_v - curr_v) / (max_v - min_v)) * 100 if inverse else ((curr_v - min_v) / (max_v - min_v)) * 100
        except: return 50.0

    @st.cache_data(ttl=3600)
    def calculate_ml_lagged_weights(_ks_s, _sp_s, _fx_s, _b10_s, _cp_s, _ma20, _vx_s):
        def find_best_lag(feature, target, max_lag=5):
            corrs = [abs(feature.shift(lag).corr(target)) for lag in range(max_lag + 1)]
            return np.argmax(corrs)
        best_lags = {'SP': find_best_lag(_sp_s, _ks_s), 'FX': find_best_lag(_fx_s, _ks_s), 'B10': find_best_lag(_b10_s, _ks_s), 'CP': find_best_lag(_cp_s, _ks_s), 'VX': find_best_lag(_vx_s, _ks_s)}
        data_rows = []
        for d in _ks_s.index[-252:]:
            s_sp = get_hist_score_val(_sp_s.shift(best_lags['SP']), d, True)
            s_fx = get_hist_score_val(_fx_s.shift(best_lags['FX']), d)
            s_b10 = get_hist_score_val(_b10_s.shift(best_lags['B10']), d)
            s_cp = get_hist_score_val(_cp_s.shift(best_lags['CP']), d, True)
            s_vx = get_hist_score_val(_vx_s.shift(best_lags['VX']), d)
            data_rows.append([ (s_fx + s_b10 + s_cp) / 3, s_sp, s_vx, max(0, min(100, 100 - (float(_ks_s.loc[d]) / float(_ma20.loc[d]) - 0.9) * 500)), _ks_s.loc[d] ])
        df_reg = pd.DataFrame(data_rows, columns=['Macro', 'Global', 'Fear', 'Tech', 'KOSPI']).replace([np.inf, -np.inf], np.nan).dropna()
        X = (df_reg.iloc[:, :4] - df_reg.iloc[:, :4].mean()) / (df_reg.iloc[:, :4].std() + 1e-6)
        Y = (df_reg['KOSPI'] - df_reg['KOSPI'].mean()) / (df_reg['KOSPI'].std() + 1e-6)
        coeffs = np.linalg.lstsq(X, Y, rcond=None)[0]
        adjusted_importance = (np.abs(coeffs) * X.std().values) + 1e-6 
        return adjusted_importance / np.sum(adjusted_importance)

    sem_w = calculate_ml_lagged_weights(ks_s, sp_s, fx_s, b10_s, cp_s, ma20, vx_s)

    st.sidebar.header("âš™ï¸ ì§€í‘œë³„ ê°€ì¤‘ì¹˜ ì„¤ì •")
    if 'slider_m' not in st.session_state: st.session_state.slider_m = float(round(sem_w[0], 2))
    if 'slider_g' not in st.session_state: st.session_state.slider_g = float(round(sem_w[1], 2))
    if 'slider_f' not in st.session_state: st.session_state.slider_f = float(round(sem_w[2], 2))
    if 'slider_t' not in st.session_state: st.session_state.slider_t = float(round(sem_w[3], 2))

    if st.sidebar.button("ğŸ”„ ê¶Œì¥ ìµœì  ê°€ì¤‘ì¹˜ë¡œ ë³µê·€"):
        st.session_state.slider_m = float(round(sem_w[0], 2)); st.session_state.slider_g = float(round(sem_w[1], 2))
        st.session_state.slider_f = float(round(sem_w[2], 2)); st.session_state.slider_t = float(round(sem_w[3], 2))
        st.rerun()

    w_macro = st.sidebar.slider("ë§¤í¬ë¡œ (í™˜ìœ¨/ê¸ˆë¦¬/ë¬¼ë™ëŸ‰)", 0.0, 1.0, key="slider_m", step=0.01)
    w_global = st.sidebar.slider("ê¸€ë¡œë²Œ ì‹œì¥ ìœ„í—˜ (ë¯¸êµ­ ì§€ìˆ˜)", 0.0, 1.0, key="slider_g", step=0.01)
    w_fear = st.sidebar.slider("ì‹œì¥ ê³µí¬ (VIX ì§€ìˆ˜)", 0.0, 1.0, key="slider_f", step=0.01)
    w_tech = st.sidebar.slider("êµ­ë‚´ ê¸°ìˆ ì  ì§€í‘œ (ì´ë™í‰ê· ì„ )", 0.0, 1.0, key="slider_t", step=0.01)

    total_w = w_macro + w_tech + w_global + w_fear
    if total_w == 0: st.error("ê°€ì¤‘ì¹˜ í•©ì´ 0ì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()

    def calculate_score(current_series, full_series, inverse=False):
        recent = full_series.tail(252)
        min_v, max_v = float(recent.min()), float(recent.max()); curr_v = float(current_series.iloc[-1])
        if max_v == min_v: return 50.0
        return float(max(0, min(100, ((max_v - curr_v) / (max_v - min_v)) * 100 if inverse else ((curr_v - min_v) / (max_v - min_v)) * 100)))

    m_now = (calculate_score(fx_s, fx_s) + calculate_score(b10_s, b10_s) + calculate_score(cp_s, cp_s, True)) / 3
    t_now = max(0.0, min(100.0, float(100 - (float(ks_s.iloc[-1]) / float(ma20.iloc[-1]) - 0.9) * 500)))
    total_risk_index = (m_now * w_macro + t_now * w_tech + calculate_score(sp_s, sp_s, True) * w_global + calculate_score(vx_s, vx_s) * w_fear) / total_w

    c_gauge, c_guide = st.columns([1, 1.6])
    with c_guide: 
        st.markdown('<p class="guide-header">ğŸ’¡ ì§€ìˆ˜ë¥¼ ë” ë˜‘ë˜‘í•˜ê²Œ ë³´ëŠ” ë²•</p>', unsafe_allow_html=True)
    with c_gauge: 
        fig_gauge = go.Figure(go.Indicator(mode="gauge+number", value=total_risk_index, title={'text': "ì£¼ì‹ ì‹œì¥ ìœ„í—˜ ì§€ìˆ˜"}))
        st.plotly_chart(fig_gauge, use_container_width=True)

    # 7. ë°±í…ŒìŠ¤íŒ… (ìµœê·¼ 1ë…„ tail ê°•ì œ ì§€ì •)
    st.markdown("---")
    st.subheader("ğŸ“‰ ì‹œì¥ ìœ„í—˜ ì§€ìˆ˜ ë°±í…ŒìŠ¤íŒ…")
    # ks_s ì¸ë±ìŠ¤ë¥¼ íƒ€ì„ì¡´ ì—†ëŠ” KST ë‚ ì§œë¡œ ì •ë ¬í•˜ì—¬ ìµœì‹  252ì¼ í™•ë³´
    dates = ks_s.tail(252).index
    hist_risks = []
    for d in dates:
        m = (get_hist_score_val(fx_s, d) + get_hist_score_val(b10_s, d) + get_hist_score_val(cp_s, d, True)) / 3
        hist_risks.append((m * w_macro + max(0, min(100, 100 - (float(ks_s.loc[d]) / float(ma20.loc[d]) - 0.9) * 500)) * w_tech + get_hist_score_val(sp_s, d, True) * w_global + get_hist_score_val(vx_s, d) * w_fear) / total_w)
    hist_df = pd.DataFrame({'Date': dates, 'Risk': hist_risks, 'KOSPI': ks_s.loc[dates].values})
    fig_bt = go.Figure()
    fig_bt.add_trace(go.Scatter(x=hist_df['Date'], y=hist_df['Risk'], name="ìœ„í—˜ ì§€ìˆ˜", line=dict(color='red')))
    fig_bt.add_trace(go.Scatter(x=hist_df['Date'], y=hist_df['KOSPI'], name="KOSPI", yaxis="y2", line=dict(color='gray', dash='dot')))
    fig_bt.update_layout(yaxis2=dict(overlaying="y", side="right"), height=400)
    st.plotly_chart(fig_bt, use_container_width=True)

    # 9. ì§€í‘œë³„ ìƒì„¸ ë¶„ì„ (ê°€ì¥ ìµœì‹  30ê°œ ë°ì´í„° tail(30) ì‚¬ìš©)
    st.markdown("---")
    st.subheader("ğŸ” ì£¼ìš” ìƒê´€ê´€ê³„ ì§€í‘œ ë¶„ì„")
    
    def create_chart(series, title, threshold, desc_text):
        # ê°œë³„ ì§€í‘œë„ ìµœì‹  252ì¼ì¹˜ë§Œ í‘œì‹œí•˜ì—¬ ë¡œë”© ì†ë„ ìµœì í™” ë° ìµœì‹ ì„± í™•ë³´
        sub_s = series.tail(252)
        fig = go.Figure(go.Scatter(x=sub_s.index, y=sub_s.values, name=title))
        fig.add_hline(y=threshold, line_width=2, line_color="red")
        return fig

    r1_c1, r1_c2, r1_c3 = st.columns(3)
    with r1_c1:
        st.plotly_chart(create_chart(sp_s, "S&P 500", sp_s.tail(252).mean()*0.9, ""), use_container_width=True)
    with r1_c2:
        fx_th = float(fx_s.tail(252).mean() * 1.02)
        st.plotly_chart(create_chart(fx_s, "ì›/ë‹¬ëŸ¬ í™˜ìœ¨", fx_th, ""), use_container_width=True)
    with r1_c3:
        st.plotly_chart(create_chart(cp_s, "Copper", cp_s.tail(252).mean()*0.9, ""), use_container_width=True)

    r2_c1, r2_c2, r2_c3 = st.columns(3)
    with r2_c1:
        st.plotly_chart(create_chart(yield_curve, "ê¸ˆë¦¬ì°¨", 0.0, ""), use_container_width=True)
    with r2_c2:
        st.subheader("KOSPI ê¸°ìˆ ì  ë¶„ì„")
        # ìˆ˜ì • í•µì‹¬: last('30D') ëŒ€ì‹  ë¬´ì¡°ê±´ ë§ˆì§€ë§‰ 30ê°œ ë¡œìš°(Row)ë¥¼ ê°€ì ¸ì˜´
        ks_recent = ks_s.tail(30)
        ma20_recent = ma20.reindex(ks_recent.index).ffill()
        
        fig_ks = go.Figure()
        # ì„  êµµê¸° ê°•í™” ë° ë°ì´í„° í¬ì¸íŠ¸ í‘œì‹œ
        fig_ks.add_trace(go.Scatter(x=ks_recent.index, y=ks_recent.values, name="í˜„ì¬ê°€", line=dict(color='royalblue', width=4), mode='lines+markers'))
        fig_ks.add_trace(go.Scatter(x=ks_recent.index, y=ma20_recent.values, name="20ì¼ì„ ", line=dict(color='orange', width=2, dash='dot')))
        
        # ì˜¤ëŠ˜ ë‚ ì§œì™€ ê°€ê²©ì„ ê·¸ë˜í”„ ìœ„ì— í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
        fig_ks.add_annotation(
            x=ks_recent.index[-1], y=ks_recent.values[-1],
            text=f"ì˜¤ëŠ˜: {ks_recent.values[-1]:.2f}",
            showarrow=True, arrowhead=1, ax=0, ay=-40,
            bgcolor="royalblue", font=dict(color="white")
        )
        
        fig_ks.update_layout(height=350, margin=dict(l=0, r=0, t=30, b=0))
        st.plotly_chart(fig_ks, use_container_width=True)
        st.info(f"ìµœì¢… ë°ì´í„° í¬ì¸íŠ¸: {ks_recent.index[-1].strftime('%Y-%m-%d')}")
        
    with r2_c3:
        st.plotly_chart(create_chart(vx_s, "VIX", 30, ""), use_container_width=True)

except Exception as e:
    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

st.caption(f"Last updated: {get_kst_now().strftime('%dì¼ %Hì‹œ %Më¶„')} | KOSPI ë°ì´í„° ì‹¤ì‹œê°„ ë°˜ì˜ ëª¨ë“œ")
