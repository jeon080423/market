import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import requests
from bs4 import BeautifulSoup
import json
from io import StringIO
from groq import Groq

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì£¼ì‹ ì‹œì¥ í•˜ë½ ì „ì¡° ì‹ í˜¸ ëª¨ë‹ˆí„°ë§", layout="wide")

# ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì • (10ë¶„ ê°„ê²©)
try:
    from streamlit_autorefresh import st_autorefresh
    st_autorefresh(interval=600000, key="datarefresh")
except ImportError:
    pass

# 2. Secretsì—ì„œ API Key ë¶ˆëŸ¬ì˜¤ê¸°
try:
    NEWS_API_KEY = st.secrets["news_api"]["api_key"]
    GROQ_API_KEY = st.secrets["groq"]["api_key"]
except KeyError:
    st.error("Secrets ì„¤ì •(API Key)ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    st.stop()

# Groq ì„¤ì • ë° ëª¨ë¸ ì´ˆê¸°í™”
try:
    client = Groq(api_key=GROQ_API_KEY)
except Exception as e:
    st.error(f"Groq ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# AI ë¶„ì„ í•¨ìˆ˜ ì •ì˜ (í• ë‹¹ëŸ‰ ë³´í˜¸ë¥¼ ìœ„í•´ ìºì‹œ ì ìš©)
@st.cache_data(ttl=3600)
def get_ai_analysis(prompt):
    try:
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
            model="llama-3.3-70b-versatile",
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"AI ë¶„ì„ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì½”ë¡œë‚˜19 í­ë½ ê¸°ì  ë‚ ì§œ ì •ì˜
COVID_EVENT_DATE = "2020-02-19"

# ê´€ë¦¬ì ì„¤ì •
try:
    ADMIN_ID = st.secrets["auth"]["admin_id"]
    ADMIN_PW = st.secrets["auth"]["admin_pw"]
except KeyError:
    ADMIN_ID = "admin_temp" 
    ADMIN_PW = "temp_pass"

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
SHEET_ID = "1eu_AeA54pL0Y0axkhpbf5_Ejx0eqdT0oFM3WIepuisU"
GSHEET_CSV_URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv"
GSHEET_WEBAPP_URL = "https://script.google.com/macros/s/AKfycbyli4kg7O_pxUOLAOFRCCiyswB5TXrA0RUMvjlTirSxLi4yz3tXH1YoGtNUyjztpDsb/exec" 

# CSS ì£¼ì…: ë ˆì´ì•„ì›ƒ ì‹œì¸ì„± ë° ë°•ìŠ¤ ë†’ì´ ìµœì í™”
st.markdown("""
    <style>
    h1 { font-size: clamp(24px, 4vw, 48px) !important; }
    .guide-header {
        font-size: clamp(18px, 2.5vw, 28px) !important;
        font-weight: 600;
        margin-bottom: 20px !important; 
        margin-top: 30px !important;    
    }
    .guide-text {
        font-size: clamp(14px, 1.2vw, 18px) !important;
        line-height: 1.6 !important;
    }
    .ai-analysis-box {
        background-color: #ffffff;
        padding: 12px 18px !important;
        border-radius: 8px;
        border: 1px solid #e0e0e0;
        border-left: 6px solid #007bff;
        line-height: 1.5 !important;
        font-size: 0.95rem !important;
        margin-bottom: 5px !important;
    }
    /* ì‚¬ì´ë“œë°” ê°€ì¤‘ì¹˜ ì•Œê³ ë¦¬ì¦˜ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    [data-testid="stExpander"] div[role="button"] p { font-weight: bold; }
    hr { margin: 1rem 0 !important; }
    </style>
    """, unsafe_allow_html=True)

def get_kst_now():
    return datetime.now() + timedelta(hours=9)

# 3. ì œëª© ë° ì„¤ëª…
st.title("KOSPI ìœ„í—˜ ëª¨ë‹ˆí„°ë§ (KOSPI Market Risk Index)")
st.markdown(f"í–¥í›„ 1ì£¼ì¼ ë‚´ì™¸ì˜ ì‹œì¥ ë³€ë™ ìœ„í—˜ í¬ì°©ìš© ëŒ€ì‹œë³´ë“œ (ì—…ë°ì´íŠ¸: {get_kst_now().strftime('%mì›” %dì¼ %Hì‹œ %Më¶„')})")
st.markdown("---")

# --- [ì•ˆë‚´ì„œ ì„¹ì…˜] ---
with st.expander("ğŸ“– ì§€ìˆ˜ ê°€ì´ë“œë¶"):
    st.subheader("1. ì§€ìˆ˜ ì‚°ì¶œ í•µì‹¬ ì§€í‘œ")
    st.write("ë³¸ ëª¨ë¸ì˜ ì§€í‘œë“¤ì€ KOSPIì™€ì˜ í†µê³„ì  ìƒê´€ê´€ê³„ ë° í•˜ë½ ì„ í–‰ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.divider()
    st.subheader("2. ì„ í–‰ì„± ë¶„ì„ ë²”ìœ„ ë° íš¨ê³¼")
    st.info("ë³¸ ìœ„í—˜ ì§€ìˆ˜ëŠ” í–¥í›„ 1ì£¼ì¼(5ê±°ë˜ì¼) ë‚´ì™¸ì˜ ë‹¨ê¸° ë³€ë™ ìœ„í—˜ í¬ì°©ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    st.divider()
    st.subheader("3. ìˆ˜ë¦¬ì  ì‚°ì¶œ ê³µì‹")
    @st.cache_data
    def get_math_formulas():
        st.markdown("#### â‘  ì‹œì°¨ ìƒê´€ê´€ê³„")
        st.latex(r"\rho(k) = \frac{Cov(X_{t-k}, Y_t)}{\sigma_{X_{t-k}} \sigma_{Y_t}}")
        st.markdown("#### â‘¡ í†µê³„ì  ë³€ë™ ê¸°ì—¬ë„ ë¶„ì„")
        st.latex(r"Importance_i = |\beta_i| \times \sigma_{X_i}")
    get_math_formulas()

# 4. ë°ì´í„° ìˆ˜ì§‘
@st.cache_data(ttl=900)
def load_data():
    end_date = datetime.now()
    start_date = "2019-01-01"
    tickers = {
        "kospi": "^KS11", "sp500": "^GSPC", "fx": "KRW=X", 
        "us10y": "^TNX", "us2y": "^IRX", "vix": "^VIX", 
        "copper": "HG=F", "freight": "BDRY", "wti": "CL=F", "dxy": "DX-Y.NYB"
    }
    data = yf.download(list(tickers.values()), start=start_date, end=end_date)['Close']
    sector_tickers = {
        "ë°˜ë„ì²´": "005930.KS", "ìë™ì°¨": "005380.KS", "2ì°¨ì „ì§€": "051910.KS",
        "ë°”ì´ì˜¤": "207940.KS", "ì¸í„°ë„·": "035420.KS", "ê¸ˆìœµ": "055550.KS"
    }
    sector_raw = yf.download(list(sector_tickers.values()), period="5d")['Close']
    return (data[[tickers["kospi"]]], data[[tickers["sp500"]]], data[[tickers["fx"]]], 
            data[[tickers["us10y"]]], data[[tickers["us2y"]]], data[[tickers["vix"]]], 
            data[[tickers["copper"]]], data[[tickers["freight"]]], data[[tickers["wti"]]], 
            data[[tickers["dxy"]]], sector_raw, sector_tickers)

# 4.5 ë‰´ìŠ¤ ìˆ˜ì§‘
@st.cache_data(ttl=1800)
def get_market_news():
    api_url = f"https://newsapi.org/v2/everything?q=stock+market+risk&sortBy=publishedAt&language=en&pageSize=5&apiKey={NEWS_API_KEY}"
    try:
        res = requests.get(api_url, timeout=10).json()
        return [{"title": a["title"], "link": a["url"]} for a in res.get("articles", [])]
    except: return []

# 4.6 ê²Œì‹œíŒ ë¡œì§
@st.cache_data(ttl=10) 
def load_board_data():
    try:
        res = requests.get(f"{GSHEET_CSV_URL}&cache_bust={datetime.now().timestamp()}", timeout=10)
        res.encoding = 'utf-8' 
        return pd.read_csv(StringIO(res.text), dtype=str).fillna("").to_dict('records')
    except: return []

def save_to_gsheet(date, author, content, password, action="append"):
    try:
        payload = {"date": str(date), "author": str(author), "content": str(content), "password": str(password), "action": action}
        if requests.post(GSHEET_WEBAPP_URL, data=json.dumps(payload), timeout=15).status_code == 200:
            st.cache_data.clear(); return True
        return False
    except: return False

try:
    with st.spinner('ë°ì´í„° ë¶„ì„ ì¤‘...'):
        kospi, sp500, fx, bond10, bond2, vix_data, copper_data, freight_data, wti_data, dxy_data, sector_raw, sector_map = load_data()

    def get_clean_series(df):
        if df is None or df.empty: return pd.Series(dtype='float64')
        if isinstance(df, pd.DataFrame): df = df.iloc[:, 0]
        return df[~df.index.duplicated(keep='first')]

    ks_s = get_clean_series(kospi).ffill()
    sp_s = get_clean_series(sp500).reindex(ks_s.index).ffill()
    fx_s = get_clean_series(fx).reindex(ks_s.index).ffill()
    b10_s = get_clean_series(bond10).reindex(ks_s.index).ffill()
    b2_s = get_clean_series(bond2).reindex(ks_s.index).ffill()
    vx_s = get_clean_series(vix_data).reindex(ks_s.index).ffill()
    cp_s = get_clean_series(copper_data).reindex(ks_s.index).ffill()
    ma20 = ks_s.rolling(window=20).mean()

    def get_hist_score_val(series, current_idx, inverse=False):
        try:
            sub = series.loc[:current_idx].iloc[-252:]
            min_v, max_v = sub.min(), sub.max(); curr_v = series.loc[current_idx]
            if max_v == min_v: return 50.0
            return ((max_v - curr_v) / (max_v - min_v)) * 100 if inverse else ((curr_v - min_v) / (max_v - min_v)) * 100
        except: return 50.0

    @st.cache_data(ttl=3600)
    def calculate_ml_lagged_weights(_ks_s, _sp_s, _fx_s, _b10_s, _cp_s, _ma20, _vx_s):
        def find_best_lag(feature, target):
            corrs = [abs(feature.shift(lag).corr(target)) for lag in range(6)]
            return np.argmax(corrs)
        best_lags = {'SP': find_best_lag(_sp_s, _ks_s), 'FX': find_best_lag(_fx_s, _ks_s), 'B10': find_best_lag(_b10_s, _ks_s), 'CP': find_best_lag(_cp_s, _ks_s), 'VX': find_best_lag(_vx_s, _ks_s)}
        data_rows = []
        for d in _ks_s.index[-252:]:
            s_sp = get_hist_score_val(_sp_s.shift(best_lags['SP']), d, True)
            s_fx = get_hist_score_val(_fx_s.shift(best_lags['FX']), d)
            s_vx = get_hist_score_val(_vx_s.shift(best_lags['VX']), d)
            s_tech = max(0, min(100, 100 - (float(_ks_s.loc[d]) / float(_ma20.loc[d]) - 0.9) * 500))
            data_rows.append([(s_fx)/1, s_sp, s_vx, s_tech, _ks_s.loc[d]])
        df_reg = pd.DataFrame(data_rows, columns=['Macro', 'Global', 'Fear', 'Tech', 'KOSPI']).dropna()
        X = (df_reg.iloc[:, :4] - df_reg.iloc[:, :4].mean()) / (df_reg.iloc[:, :4].std() + 1e-6)
        Y = (df_reg['KOSPI'] - df_reg['KOSPI'].mean()) / (df_reg['KOSPI'].std() + 1e-6)
        coeffs = np.linalg.lstsq(X, Y, rcond=None)[0]
        adj_imp = (np.abs(coeffs) * X.std().values) + 1e-6 
        return adj_imp / np.sum(adj_imp)

    sem_w = calculate_ml_lagged_weights(ks_s, sp_s, fx_s, b10_s, cp_s, ma20, vx_s)

    # 5. ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì§€í‘œë³„ ê°€ì¤‘ì¹˜ ì„¤ì •")
    w_macro = st.sidebar.slider("ë§¤í¬ë¡œ", 0.0, 1.0, float(round(sem_w[0], 2)), 0.01)
    w_global = st.sidebar.slider("ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬", 0.0, 1.0, float(round(sem_w[1], 2)), 0.01)
    w_fear = st.sidebar.slider("ì‹œì¥ ê³µí¬", 0.0, 1.0, float(round(sem_w[2], 2)), 0.01)
    w_tech = st.sidebar.slider("êµ­ë‚´ ê¸°ìˆ ì§€í‘œ", 0.0, 1.0, float(round(sem_w[3], 2)), 0.01)

    with st.sidebar.expander("â„¹ï¸ ê°€ì¤‘ì¹˜ ì‚°ì¶œ ì•Œê³ ë¦¬ì¦˜"):
        st.caption("ì„ í˜• íšŒê·€(OLS) í†µê³„ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê³¼ê±° ë°ì´í„°ìƒ ê° íŒ©í„°ì˜ ì˜í–¥ë ¥ì„ ì—­ì‚°í•©ë‹ˆë‹¤.")

    # ìœ„í—˜ ì§€ìˆ˜ ê³„ì‚°
    m_now = calculate_score = lambda s, i: float(max(0, min(100, ((s.last('365D').max() - s.iloc[-1]) / (s.last('365D').max() - s.last('365D').min())) * 100 if i else ((s.iloc[-1] - s.last('365D').min()) / (s.last('365D').max() - s.last('365D').min())) * 100)))
    total_risk = (m_now(fx_s, False) * w_macro + m_now(sp_s, True) * w_global + m_now(vx_s, False) * w_fear + max(0, min(100, 100 - (float(ks_s.iloc[-1])/float(ma20.iloc[-1]) - 0.9)*500)) * w_tech) / (w_macro+w_global+w_fear+w_tech)

    # ê²Œì´ì§€ ì°¨íŠ¸
    c_gauge, c_guide = st.columns([1, 1.6])
    with c_gauge:
        fig_gauge = go.Figure(go.Indicator(mode="gauge+number", value=total_risk, title={'text': "ì‹œì¥ ìœ„í—˜ ì§€ìˆ˜"}, gauge={'axis': {'range': [0, 100]}, 'bar': {'color': "black"}, 'steps': [{'range': [0, 40], 'color': "green"}, {'range': [40, 70], 'color': "orange"}, {'range': [70, 100], 'color': "red"}]}))
        fig_gauge.update_layout(height=350, margin=dict(l=20, r=20, t=50, b=20)); st.plotly_chart(fig_gauge, use_container_width=True)
    with c_guide:
        st.markdown('<p class="guide-header">ğŸ’¡ ì§€ìˆ˜ í•´ì„ ê°€ì´ë“œ</p>', unsafe_allow_html=True)
        st.markdown('<div class="guide-text">0-40: ì•ˆì •ê¸° (ì ê·¹ íˆ¬ì ê³ ë ¤)<br>40-70: ì£¼ì˜ë³´ (ë¹„ì¤‘ ì¡°ì ˆ ì‹œì‘)<br>70-100: ìœ„í—˜ê¸° (í˜„ê¸ˆ ë¹„ì¤‘ í™•ëŒ€)</div>', unsafe_allow_html=True)

    st.markdown("---")
    cn, cr = st.columns(2)
    with cn:
        st.subheader("ğŸ“° ê¸€ë¡œë²Œ ê²½ì œ ë‰´ìŠ¤ (AI ìš”ì•½)")
        news_data = get_market_news()
        all_titles = ". ".join([n['title'] for n in news_data])
        if news_data:
            with st.spinner("ë¶„ì„ ì¤‘..."):
                prompt = f"ê²½ì œ ë‰´ìŠ¤ ì œëª©ë“¤: {all_titles}\ní•µì‹¬ ë¦¬ìŠ¤í¬ì™€ ìœ ì˜ì ì„ í•œêµ­ì–´ ë¬¸ì¥ 2ê°œë¡œ ë¶„ì„í•´ì¤˜. ì§€ì¹¨: 1. í•œìë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆ. 2. ë³„í‘œ(**) ê°™ì€ ê°•ì¡° ê¸°í˜¸ë¥¼ ì“°ì§€ ë§ˆ. 3. ë¬¸ë²•ì— ë§ëŠ” í‘œì¤€ í•œêµ­ì–´ë§Œ ì‚¬ìš©í•´."
                summary = get_ai_analysis(prompt).replace('**', '').strip()
                st.markdown(f'<div class="ai-analysis-box"><strong>ğŸ” AI ë‰´ìŠ¤ í†µí•© ë¶„ì„</strong><br>{summary}</div>', unsafe_allow_html=True)

    with cr:
        st.subheader("ğŸ¤– ì‹œì¥ ì§€í‘œ ì¢…í•© ì§„ë‹¨")
        latest_summary = f"S&P500: {sp_s.iloc[-1]:.0f}, í™˜ìœ¨: {fx_s.iloc[-1]:.1f}, VIX: {vx_s.iloc[-1]:.1f}"
        with st.spinner("ì§„ë‹¨ ì¤‘..."):
            ai_desc_prompt = f"ë°ì´í„°: {latest_summary}\ní•œêµ­ ì¦ì‹œ ìƒí™©ì„ ì§„ë‹¨í•´ì¤˜. ì§€ì¹¨: 1. í•œìë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆ. 2. [ì£¼ìš” ì§€í‘œ ìš”ì•½]ê³¼ [ì‹œì¥ ì§„ë‹¨ ë° ì „ë§] ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ë˜ ë³„í‘œ(**) ê¸°í˜¸ë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆ. 3. ë°•ìŠ¤ í¬ê¸°ë¥¼ ê³ ë ¤í•´ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´."
            analysis = get_ai_analysis(ai_desc_prompt).replace('**', '').strip()
            st.markdown(f'<div class="ai-analysis-box">{analysis}</div>', unsafe_allow_html=True)

    # 7. ë°±í…ŒìŠ¤íŒ… ë° ì°¨íŠ¸
    st.markdown("---")
    st.subheader("ğŸ“ˆ ì£¼ìš” ì§€í‘œ ì¶”ì„¸ ë¶„ì„")
    col1, col2, col3 = st.columns(3)
    def small_chart(series, title):
        fig = go.Figure(go.Scatter(x=series.index, y=series.values, name=title))
        fig.update_layout(height=250, margin=dict(l=0, r=0, t=30, b=0), title=title); return fig
    col1.plotly_chart(small_chart(sp_s.last('90D'), "ë¯¸êµ­ S&P 500"), use_container_width=True)
    col2.plotly_chart(small_chart(fx_s.last('90D'), "ì›/ë‹¬ëŸ¬ í™˜ìœ¨"), use_container_width=True)
    col3.plotly_chart(small_chart(vx_s.last('90D'), "VIX ê³µí¬ ì§€ìˆ˜"), use_container_width=True)

except Exception as e:
    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

st.caption(f"Last updated: {get_kst_now().strftime('%dì¼ %Hì‹œ %Më¶„')} | NewsAPI & Groq AI")
